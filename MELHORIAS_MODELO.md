# üîß Melhorias Implementadas para o Modelo

## üìä Problema Identificado

O modelo estava extremamente desbalanceado:
- **Recall = 1.0** (detecta todos os manipulados) ‚úÖ
- **Specificity = 0.1** (s√≥ acerta 10% dos aut√™nticos) ‚ùå
- **FPR = 0.9** (90% de falsos positivos) ‚ùå

O modelo estava classificando quase tudo como "manipulado".

## ‚úÖ Solu√ß√µes Implementadas

### 1. **Class Weights no Loss Function**

Adicionado balanceamento autom√°tico de classes no treinamento:

```python
# Calcula pesos inversamente proporcionais √† frequ√™ncia das classes
class_weights = torch.tensor([
    total / (2 * count_authentic),  # Peso maior para classe minorit√°ria
    total / (2 * count_manipulated)
])
loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)
```

**Como usar:**
- O treinamento agora calcula automaticamente os pesos
- Classes menos frequentes recebem peso maior
- Isso for√ßa o modelo a prestar mais aten√ß√£o na classe minorit√°ria

### 2. **M√©tricas Detalhadas por Classe**

Agora o treinamento mostra m√©tricas separadas:
```
üìå √âpoca 1/3 ‚Äî Loss: 13.48 | Acc: 56.25%
   Authentic: 45.0% (9/20) | Manipulated: 67.5% (27/40)
```

Isso permite monitorar o balanceamento durante o treino.

### 3. **Script de Ajuste de Threshold**

Criado `src/evaluate_with_threshold.py` para encontrar o threshold √≥timo:

```bash
# Encontrar threshold √≥timo automaticamente
python src/evaluate_with_threshold.py

# Testar threshold espec√≠fico
python src/evaluate_with_threshold.py --threshold 0.6
```

**O que faz:**
- Testa thresholds de 0.3 a 0.8
- Encontra o threshold com melhor F1-score balanceado
- Mostra confusion matrix para cada threshold
- Salva an√°lise em `reports/threshold_analysis.json`

## üöÄ Como Aplicar as Melhorias

### Passo 1: Retreinar com Class Weights

```bash
python run_train.py
```

O modelo agora ser√° treinado com class weights, o que deve melhorar o balanceamento.

### Passo 2: Encontrar Threshold √ìtimo

```bash
python src/evaluate_with_threshold.py
```

Isso vai testar diferentes thresholds e mostrar qual d√° o melhor resultado.

### Passo 3: Aplicar Threshold na Infer√™ncia

Voc√™ pode modificar `src/evaluate.py` ou `src/api/main.py` para usar o threshold √≥timo:

```python
# Em vez de:
pred_idx = torch.argmax(probs, dim=1)

# Use:
prob_manipulated = probs[0, 1].item()
threshold = 0.6  # Threshold √≥timo encontrado
pred_idx = 1 if prob_manipulated >= threshold else 0
```

## üìà Pr√≥ximas Melhorias Sugeridas

### 1. **Aumentar Dataset**
- Gerar mais dados sint√©ticos (200+ de cada classe)
- Adicionar dados reais se poss√≠vel

### 2. **Data Augmentation Mais Agressiva**
- Adicionar mais transforma√ß√µes visuais
- Varia√ß√µes de texto (sin√¥nimos, par√°frases)

### 3. **Oversampling (SMOTE)**
```python
from imblearn.over_sampling import SMOTE
# Aplicar SMOTE nos embeddings antes do treino
```

### 4. **Focal Loss**
Substituir CrossEntropyLoss por Focal Loss, que foca em exemplos dif√≠ceis:

```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()
```

### 5. **Calibra√ß√£o de Probabilidades**
```python
from sklearn.calibration import CalibratedClassifierCV
# Calibrar probabilidades ap√≥s o treino
```

### 6. **Early Stopping com Valida√ß√£o**
Adicionar valida√ß√£o durante o treino para evitar overfitting:

```python
# Validar a cada √©poca e parar se n√£o melhorar
if val_f1 < best_f1:
    patience += 1
    if patience >= 3:
        break
```

## üìù Checklist de Melhorias

- [x] Class weights no loss function
- [x] M√©tricas detalhadas por classe
- [x] Script de an√°lise de threshold
- [ ] Aumentar tamanho do dataset
- [ ] Implementar Focal Loss
- [ ] Adicionar early stopping
- [ ] Calibra√ß√£o de probabilidades
- [ ] Oversampling (SMOTE)

## üéØ Resultados Esperados

Ap√≥s aplicar as melhorias, voc√™ deve ver:

- **Specificity > 0.5** (pelo menos 50% dos aut√™nticos corretos)
- **FPR < 0.5** (menos de 50% de falsos positivos)
- **F1-Score balanceado** (n√£o s√≥ alto recall)
- **Confusion Matrix mais equilibrada**

---

**Execute `python run_train.py` para retreinar com as melhorias!** üöÄ


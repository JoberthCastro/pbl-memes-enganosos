import os
import pandas as pd
import torch
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split

from src.dataset import MemeDataset
from src.preprocessing import get_transforms
from src.text_model import Tokenizer, TextModel
from src.visual_extractor import VisualExtractor
from src.fusion_model import FusionModel


CSV_PATH = "data/labels.csv"
TRAIN_CSV_PATH = "data/train_labels.csv"
TEST_CSV_PATH = "data/test_labels.csv"
DATA_DIR = "data/raw"
MODEL_DIR = "models"

os.makedirs(MODEL_DIR, exist_ok=True)


def train(num_epochs: int = 3, batch_size: int = 4, lr: float = 1e-4, dropout_rate: float = 0.5):
    """
    Treina o modelo de fus√£o.
    Args:
        num_epochs: N√∫mero de √©pocas.
        batch_size: Tamanho do batch.
        lr: Taxa de aprendizado.
        dropout_rate: Taxa de dropout para regulariza√ß√£o (combater overfitting).
    """
    print("üì¶ Lendo labels...")
    if not os.path.exists(CSV_PATH):
        raise FileNotFoundError(
            f"labels.csv n√£o encontrado em {CSV_PATH}. Rode:  python data/synthetic_generator.py"
        )

    df = pd.read_csv(CSV_PATH)
    
    # Separa√ß√£o Treino / Teste (80% / 20%)
    print("‚úÇ Separando dados de Treino e Teste...")
    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)
    
    # Salvar os CSVs separados para que o evaluate.py possa usar o test_df
    train_df.to_csv(TRAIN_CSV_PATH, index=False)
    test_df.to_csv(TEST_CSV_PATH, index=False)
    print(f"   Treino: {len(train_df)} amostras -> Salvo em {TRAIN_CSV_PATH}")
    print(f"   Teste:  {len(test_df)} amostras -> Salvo em {TEST_CSV_PATH}")

    texts = train_df["original_text_content"].astype(str).tolist()

    print("üìù Criando tokenizer...")
    tokenizer = Tokenizer(num_words=10000)
    tokenizer.fit_on_texts(texts)

    print("üñº Preparando dataset de TREINO...")
    # Aumenta√ß√£o de dados (Data Augmentation) no treino para combater overfitting
    # O get_transforms('train') j√° deve ter algumas transforma√ß√µes, mas garantir que sejam robustas.
    transform = get_transforms(mode="train")
    dataset = MemeDataset(
        csv_file=TRAIN_CSV_PATH, # Usar apenas o CSV de treino
        root_dir=DATA_DIR,
        tokenizer=tokenizer,
        max_len=100,
        transform=transform,
    )
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    print("üé® Carregando modelo visual...")
    # FREEZE BACKBONE: True para evitar overfitting em dataset pequeno/sint√©tico
    visual = VisualExtractor(model_name="mobilenet_v2", pretrained=True, freeze_backbone=True)

    print("‚úç Carregando modelo textual...")
    text_model = TextModel(
        vocab_size=len(tokenizer.word_index) + 2,
        embedding_dim=128,
        hidden_dim=128
    )

    print("üîó Carregando modelo de fus√£o...")
    # Passando dropout para o modelo de fus√£o se ele suportar (ou garantindo via c√≥digo)
    # Aqui assumimos que o FusionModel tem camadas internas ou usamos weight_decay no otimizador.
    fusion = FusionModel({
        "num_classes": 2,
        "text_output_dim": text_model.output_dim
    })

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üìå Usando dispositivo: {device}")

    visual.to(device)
    text_model.to(device)
    fusion.to(device)

    # Combater Overfitting: Adicionar weight_decay (L2 Regularization)
    optimizer = torch.optim.Adam(
        list(visual.parameters()) +
        list(text_model.parameters()) +
        list(fusion.parameters()),
        lr=lr,
        weight_decay=1e-4  # L2 Regularization
    )

    loss_fn = torch.nn.CrossEntropyLoss()

    print("üöÄ Iniciando treinamento...\n")

    for epoch in range(num_epochs):
        epoch_loss = 0
        correct = 0
        total = 0

        visual.train()
        text_model.train()
        fusion.train()

        for images, tokens, labels in dataloader:
            images = images.to(device)
            tokens = tokens.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            v_emb = visual(images)
            t_emb = text_model(tokens)

            # OCR stats zerados (treino b√°sico)
            ocr_stats = torch.zeros(images.size(0), 3, device=device)

            logits = fusion(v_emb, t_emb, ocr_stats)
            loss = loss_fn(logits, labels)

            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

            preds = logits.argmax(dim=1)
            total += labels.size(0)
            correct += (preds == labels).sum().item()

        acc = correct / total * 100
        print(f"üìå √âpoca {epoch+1}/{num_epochs} ‚Äî Loss: {epoch_loss:.4f} | Acc: {acc:.2f}%")

    print("\nüíæ Salvando pesos...")
    torch.save(visual.state_dict(), os.path.join(MODEL_DIR, "visual_model.pth"))
    torch.save(text_model.state_dict(), os.path.join(MODEL_DIR, "text_model.pth"))
    torch.save(fusion.state_dict(), os.path.join(MODEL_DIR, "fusion_model.pth"))

    print("üéâ Treinamento conclu√≠do com sucesso!")


if __name__ == "__main__":
    # Reduzi epochs para 3 para evitar decorar demais, mas com weight_decay ativado.
    train(num_epochs=3)
